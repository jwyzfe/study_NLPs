{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets huggingface_hub fsspec==2024.10.0 -qqq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T07:59:03.233144Z","iopub.execute_input":"2025-02-04T07:59:03.233466Z","iopub.status.idle":"2025-02-04T07:59:10.589354Z","shell.execute_reply.started":"2025-02-04T07:59:03.233436Z","shell.execute_reply":"2025-02-04T07:59:10.588443Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\ns3fs 2024.9.0 requires fsspec==2024.9.0.*, but you have fsspec 2024.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\n#os.environ[\"OPENAI_API_KEY\"] =\n# os.environ[\"HF_TOKEN\"] = ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T01:15:04.680179Z","iopub.execute_input":"2025-02-05T01:15:04.680534Z","iopub.status.idle":"2025-02-05T01:15:04.685144Z","shell.execute_reply.started":"2025-02-05T01:15:04.680507Z","shell.execute_reply":"2025-02-05T01:15:04.683776Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## huggingface tokenizer\n- decode\n- encode\n- convert","metadata":{}},{"cell_type":"code","source":"# https://huggingface.co/klue/roberta-base\n# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\n\nroberta_tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\nroberta_tokenizer\n#model = AutoModelForMaskedLM.from_pretrained(\"klue/roberta-base\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T00:35:21.386546Z","iopub.execute_input":"2025-02-05T00:35:21.386865Z","iopub.status.idle":"2025-02-05T00:35:23.078178Z","shell.execute_reply.started":"2025-02-05T00:35:21.386837Z","shell.execute_reply":"2025-02-05T00:35:23.077083Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba4d63e27082436eaf2d13959a17f524"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee2e63e4241c41ceb90012f150c3e233"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/752k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e667ee85b6ca426e9b296fe079fb739f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14bc70a24ebc406e81dd347bc46fa0f9"}},"metadata":{}},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"BertTokenizerFast(name_or_path='klue/roberta-base', vocab_size=32000, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t3: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}\n)"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"text = '토크나이저는 텍스트를 사전에 있는 기준으로 토큰 단위로 나눈다.'\n#tokenized_text = roberta_tokenizer(text)  #encode\ntokenized_text = roberta_tokenizer.encode(text)  #encode\n#tokenized_text = roberta_tokenizer.encode(text, add_special_tokens=False)  #encode\n\n\ntokenized_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T08:35:33.282381Z","iopub.execute_input":"2025-02-04T08:35:33.282701Z","iopub.status.idle":"2025-02-04T08:35:33.289017Z","shell.execute_reply.started":"2025-02-04T08:35:33.282666Z","shell.execute_reply":"2025-02-04T08:35:33.288182Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[0,\n 9157,\n 7461,\n 2190,\n 2259,\n 8509,\n 2138,\n 4858,\n 2170,\n 1513,\n 2259,\n 3872,\n 6233,\n 1793,\n 2855,\n 5385,\n 2200,\n 20950,\n 18,\n 2]"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"roberta_tokenizer.convert_ids_to_tokens(tokenized_text['input_ids'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T08:18:13.137187Z","iopub.execute_input":"2025-02-04T08:18:13.137501Z","iopub.status.idle":"2025-02-04T08:18:13.142724Z","shell.execute_reply.started":"2025-02-04T08:18:13.137471Z","shell.execute_reply":"2025-02-04T08:18:13.141986Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['[CLS]',\n '토크',\n '##나이',\n '##저',\n '##는',\n '텍스트',\n '##를',\n '사전',\n '##에',\n '있',\n '##는',\n '기준',\n '##으로',\n '토',\n '##큰',\n '단위',\n '##로',\n '나눈다',\n '.',\n '[SEP]']"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"roberta_tokenizer.decode(tokenized_text['input_ids'], skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T08:32:00.390252Z","iopub.execute_input":"2025-02-04T08:32:00.390582Z","iopub.status.idle":"2025-02-04T08:32:00.396264Z","shell.execute_reply.started":"2025-02-04T08:32:00.390547Z","shell.execute_reply":"2025-02-04T08:32:00.395325Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'토크나이저는 텍스트를 사전에 있는 기준으로 토큰 단위로 나눈다.'"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"## 여러 문장 변경","metadata":{}},{"cell_type":"code","source":"texts = ['첫 번째 문장 넣기', '두 번째 문장 작성 넣기']\n\n#tokenized_texts = roberta_tokenizer.batch_encode(texts)\ntokenized_texts = roberta_tokenizer(texts)\ntokenized_texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T00:38:47.780268Z","iopub.execute_input":"2025-02-05T00:38:47.780848Z","iopub.status.idle":"2025-02-05T00:38:47.799200Z","shell.execute_reply.started":"2025-02-05T00:38:47.780811Z","shell.execute_reply":"2025-02-05T00:38:47.798040Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[0, 1656, 1141, 3135, 6265, 751, 2015, 2], [0, 864, 1141, 3135, 6265, 5159, 751, 2015, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]]}"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"roberta_tokenizer.batch_decode(tokenized_texts['input_ids'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T00:38:47.800856Z","iopub.execute_input":"2025-02-05T00:38:47.801169Z","iopub.status.idle":"2025-02-05T00:39:07.335853Z","shell.execute_reply.started":"2025-02-05T00:38:47.801144Z","shell.execute_reply":"2025-02-05T00:39:07.334546Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['[CLS] 첫 번째 문장 넣기 [SEP]', '[CLS] 두 번째 문장 작성 넣기 [SEP]']"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## 모델별 별도 토큰이 필요한 이유","metadata":{}},{"cell_type":"code","source":"texts_kr = ['첫 번째 문장 넣기', '두 번째 문장 작성 넣기']\ntexts_eng = ['input first sentence','input second sentence']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T00:39:07.338279Z","iopub.execute_input":"2025-02-05T00:39:07.338949Z","iopub.status.idle":"2025-02-05T00:39:07.343981Z","shell.execute_reply.started":"2025-02-05T00:39:07.338916Z","shell.execute_reply":"2025-02-05T00:39:07.342508Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"bert_kr_tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\nprint(bert_kr_tokenizer(texts_kr))\nprint(bert_kr_tokenizer(texts_eng))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T00:39:07.345375Z","iopub.execute_input":"2025-02-05T00:39:07.345818Z","iopub.status.idle":"2025-02-05T00:39:08.903680Z","shell.execute_reply.started":"2025-02-05T00:39:07.345774Z","shell.execute_reply":"2025-02-05T00:39:08.902484Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d36756af886340449b478bab79f973d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b1d7387197940b2b1c171f821d8fcc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"569d36ea48de4abb8e0c59b9e0872005"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cf256655712424aa46da7e600f7d9ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"538609b9c88c4302be9ae6a8a83cfe4f"}},"metadata":{}},{"name":"stdout","text":"{'input_ids': [[2, 1656, 1141, 3135, 6265, 751, 2015, 3], [2, 864, 1141, 3135, 6265, 5159, 751, 2015, 3]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n{'input_ids': [[2, 5011, 2006, 6449, 73, 24507, 17219, 30062, 9963, 3], [2, 5011, 2006, 6449, 29318, 10613, 17219, 30062, 9963, 3]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"roberta_kr_tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T00:39:08.904826Z","iopub.execute_input":"2025-02-05T00:39:08.905123Z","iopub.status.idle":"2025-02-05T00:39:09.090406Z","shell.execute_reply.started":"2025-02-05T00:39:08.905098Z","shell.execute_reply":"2025-02-05T00:39:09.089153Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\nroberta_eng_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\nprint(roberta_eng_tokenizer(texts_kr))\nprint(roberta_eng_tokenizer(texts_eng))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T00:39:09.091943Z","iopub.execute_input":"2025-02-05T00:39:09.092249Z","iopub.status.idle":"2025-02-05T00:39:10.998126Z","shell.execute_reply.started":"2025-02-05T00:39:09.092225Z","shell.execute_reply":"2025-02-05T00:39:10.996740Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5a9cef08bbf4aa6b8cc6949ae968a5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1852bd536cad4918b2d90b6cf05837f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e3f949cd2574782b1c0b144da94448e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80eefaab3f304ca69888815d514b0d5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea3b9d5aa86949d4a2ab1345270be78f"}},"metadata":{}},{"name":"stdout","text":"{'input_ids': [[0, 43998, 14292, 4958, 47672, 14292, 23133, 43998, 6248, 18537, 47672, 11582, 18537, 43998, 17772, 8210, 47672, 11936, 2469, 46873, 18537, 7487, 2], [0, 45209, 3602, 16948, 47672, 14292, 23133, 43998, 6248, 18537, 47672, 11582, 18537, 43998, 17772, 8210, 46747, 17772, 3602, 43998, 11936, 15389, 47672, 11936, 2469, 46873, 18537, 7487, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n{'input_ids': [[0, 46797, 78, 3645, 2], [0, 46797, 200, 3645, 2]], 'attention_mask': [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}